<h2>Introduction</h2>
The following project represents a comprehensive data analysis project centered around housing data using the R programming language. The project begins by loading the Ames Housing dataset from a CSV file named "AmesHousing-3.csv" into a dataframe named "ames." This dataset encompasses a wide range of attributes related to houses, including zoning classification, lot characteristics, building type, house style, quality and condition ratings, construction details, and sale-related features. The use of libraries such as tidyverse, dplyr, ggplot2, and lessR underscores the project's emphasis on efficient data manipulation, visualization, and analysis.

<H2>Exploratory Data Analysis</H2>
<p>Upon loading the data, the code provides a glimpse into the structure and content of the dataset by displaying the first 25 entries using the head() function. This step allows for a quick assessment of the dataset's columns and initial data points. Following this, a comprehensive summary of the dataset is generated using the summary() function. This summary offers crucial statistics for numerical variables, such as mean, median, quartiles, minimum, and maximum values. Additionally, it highlights potential areas of interest by identifying columns with missing values, such as "Lot.Frontage," signaling the need for data cleaning and preprocessing.</p>
<p>The project's analytical depth is further demonstrated through the use of various functions and methods for data exploration. For instance, the code employs the group_by() and summarize() functions to investigate average sale prices based on different house styles. Visualizations, including scatter plots and bar charts, are created using ggplot2 to enhance the understanding of relationships between variables. The inclusion of exploratory data analysis techniques underscores the project's commitment to uncovering patterns and insights within the housing dataset.Moreover, the code illustrates a keen interest in identifying and handling outliers within the data. The implementation of outlier detection through the use of the interquartile range (IQR) and subsequent removal of outliers contributes to the project's commitment to ensuring data quality and reliability.</p>

![Screenshot 2024-01-18 at 6 45 44 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/3a900e05-edeb-4572-af32-152e2dc240b6)
![Screenshot 2024-01-18 at 6 45 59 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/dae03dda-b107-43fa-a21e-eb82b6bd14a3)
![Screenshot 2024-01-18 at 6 46 08 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/c8bd2135-20db-41ff-b06c-c42962913630)
![Screenshot 2024-01-18 at 6 47 54 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/13ce5253-addc-4688-bb8e-c8ff8ce28c6e)

<p>One of the visualizations involves a barplot illustrating the distribution of houses based on different styles. Another scatter plot examines the correlation between plot area and house sale prices, pinpointing potential outliers and advantageous deals.The code addresses missing values in specific columns by replacing them with the mean of the respective columns. A comprehensive dataset summary is provided, highlighting value distributions and ensuring a check for any remaining NULL values. A boxplot is generated to depict the distribution of numerical data, emphasizing outliers, particularly in Lot Area and Sale Price variables. Furthermore, a correlation matrix is computed, showcasing the relationships between numerical variables. A correlation plot, constructed using the 'corrplot' library, visually represents these correlations, with notable emphasis on the strong correlation between Gr.Liv.Area and TotRms.AbvGrd.</p>

![Screenshot 2024-01-18 at 6 33 18 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/a8100354-736a-4086-a8b5-97e60976ab5b)


<p>Examining the four diagnostic graphs reveals some interesting details about the analyzed data. While the Normal Q-Q plot suggests reassuring normality, the Residuals vs Fitted and Scale-Location plots raise concerns. Outliers appear to be present, and homoscedasticity (equal variance) might be an issue. The Residuals vs Leverage plot will be crucial in identifying the specific influential data points responsible for these concerns. Further investigation is warranted to address these findings and ensure the validity of any statistical conclusions drawn from the data.</p>

![Screenshot 2024-01-18 at 6 33 27 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/97971b73-b6c7-4e29-b993-a665461a6ca2)
<p>The influence plot raises concerns about potential heteroscedasticity in the model. The spread of residuals across the graph provides a visual clue, while the Cook's D statistic pinpoints specific data points (1499 and 2181) that exert undue influence on the model's fit. These points, with their high Cook's D values, are prime candidates for further investigation as potential outliers. Examining their characteristics and distribution in the data is crucial for ensuring the validity of the model and any conclusions drawn from it. Addressing these influential points through appropriate methods, such as outlier removal or robust regression techniques, might be necessary to achieve a more reliable model.</p>

![Screenshot 2024-01-18 at 6 37 16 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/7a7f58f2-c588-455e-8675-819e60d743a2)
<p>Choosing the best regression model for our house pricing data requires careful consideration of both model fit and complexity. The plot of adjusted R-squared values provides valuable insights. While a simpler model with only Intercept and Gr.Liv.Area achieves an adjusted R-squared of 0.5, models incorporating additional relevant variables like Total Bsmt.SF and Garage.Area demonstrate progressively better fit, ultimately reaching a peak of 0.68. This model, including all key variables, emerges as the optimal choice, striking a balance between accurate prediction and avoiding overfitting by keeping the variable count reasonable. Therefore, for reliable house price predictions, a regression model encompassing Intercept, Total Bsmt.SF, Garage.Area, and Gr.Liv.Area is recommended.</p>

![Screenshot 2024-01-18 at 6 37 25 PM](https://github.com/sadhale-shreyas/housing_data_analysis/assets/143985440/8bab2411-0f35-41a0-a709-0ec7796299d5)

<p>Selecting the best regression model for predicting house prices involved a robust two-pronged approach. Through careful examination of both adjusted R-squared and Cp values, a clear winner emerged. Both metrics pointed towards the same model, incorporating all four key variables: Intercept, Total Bsmt.SF, Garage.Area, and Gr.Liv.Area. This model showcased superior fit without overfitting, achieving an adjusted R-squared of 0.68 and the lowest Cp value of 4. This consistency reinforces its validity, making it the definitive choice for accurate house price predictions.</p>

<h2>Conclusion:</h2>
<p>In conclusion, the analysis of the regression model for house pricing based on the 'ames' dataset reveals important insights and considerations. The diagnostic graphs, including the Normal Q-Q plot, Residuals vs Fitted, Scale-Location, and Residuals vs Leverage plots, highlight potential issues with outliers and homoscedasticity. Further investigation, particularly focusing on influential data points identified by the influence plot and Cook's D statistic, is essential to ensure the model's validity and reliability for statistical inferences.</p>
<p>Addressing potential heteroscedasticity through methods such as outlier removal or robust regression is recommended. The thorough examination of model fit and complexity, considering adjusted R-squared values, guides the selection of the optimal regression model. The chosen model, encompassing Intercept, Total Bsmt.SF, Garage.Area, and Gr.Liv.Area, strikes a balance between accuracy and simplicity, avoiding overfitting.</p>
